# MarkovDecisionProcess

MDP is tested by TestMDP

RL is tested by TestRL

In these two test, there are 4 states in state space and 2 actions in action space.

You can print policy and V(value funtion) to check the result.

The fianl policy is (0, 1, 1, 1) given the transition function and reward function in the code.



Then you can test MDP and RL on the TestMDPmaze and TestRLmaze.

For TestMDPmaze, the final policy is [3 3 1 1 3 0 1 1 1 3 3 1 3 3 0 2 0] given the transition function and reward function in the code.

For TestRLmaze, there are two graphs to be produced. Graph 1 shows the result of Îµ-greedy exploration comparison. Graph 2 shows the result of Boltzmann temperature comparison. More detailed explaination of the graph are saved in ResultExplaination.txt.


